# Bias Auditing and Explainable AI Prototype for Immigration Visa Decisioning

This project demonstrates a responsible AI system using:
- âœ… Fairness auditing (AIF360)
- âœ… Explainability (LIME)
- âœ… Visa decision prediction (Logistic Regression)
- âœ… Deployed as a REST API via FastAPI

### ğŸš€ API Endpoints
- `POST /predict` â€“ Returns visa decision (Accepted/Rejected)
- `POST /explain` â€“ Returns LIME explanation for the decision
- `GET /audit` â€“ Returns fairness metrics (disparate impact, mean difference)

### ğŸ§ª Example input
```json
{
  "age": 25,
  "priors_count": 1,
  "race": 0
}
```

---

### âš™ï¸ Deployment on Railway
1. Create a new project on [https://railway.app](https://railway.app)
2. Upload all files:
   - `visa_ai_fastapi_backend.py`
   - `requirements.txt`
   - `Procfile`
3. Set the root directory and deploy the service
4. Use the generated URL (e.g. `https://visa-ai.up.railway.app/docs`) to access the Swagger UI

---

### âœ… Notes
- The model is trained on a subset of the COMPAS dataset (age, priors_count, race)
- Bias auditing uses AIF360
- No database is required â€“ model is trained at startup
- Adjust features easily to expand the prototype